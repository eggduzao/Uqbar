{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9bafb38-b625-49eb-83a0-95241cf5c613",
   "metadata": {},
   "source": [
    "# Selenium Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ddd2a-1568-4d17-b9b6-c85e1225466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from collections.abc import Generator, Iterator\n",
    "from datetime import datetime as dt\n",
    "import difflib\n",
    "from io import BytesIO\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import requests\n",
    "from time import sleep, time\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.common.exceptions import (\n",
    "    StaleElementReferenceException,\n",
    "    TimeoutException,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6e42c-11cf-41b2-9409-640b2966764d",
   "metadata": {},
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a2b45-28a9-429b-b8bd-19121c09e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "SEARCH_URL: str = f\"https://duckduckgo.com/?q=\"\n",
    "\n",
    "\n",
    "NORMAL_GENERATOR: Generator = np.random.default_rng()\n",
    "\n",
    "NORMAL_MEAN: float = 0.5\n",
    "NORMAL_STD: float = 0.3\n",
    "NORMAL_SIZE: float = 1\n",
    "\n",
    "\n",
    "# WebElement search dictionary where key is a title pointing to a vector with:\n",
    "# [By name, By value, #empirical possible, #actual possible]\n",
    "ELEMENT_DICT: dict[str, list[str]] = {\n",
    "    # \"html\": [By.TAG_NAME, \"html\", 1, 1],\n",
    "    \"body\": [By.TAG_NAME, \"body\", 1, 1],\n",
    "    \"web\": [By.ID, \"web_content_wrapper\", 1, 1],\n",
    "    # \"xpath_1\": [By.XPATH, \"//*[@id=\\\"react-layout\\\"]\", 1, 1],\n",
    "    \"xpath\": [By.XPATH, \"//*\", 5188, 5188],\n",
    "    \"section\": [By.TAG_NAME, \"section\", 21, 6],\n",
    "    \"ol_1\": [By.TAG_NAME, \"ol\", 47, 9],\n",
    "    \"ol_2\": [By.TAG_NAME, \"ol\", 126, 9],\n",
    "    \"figure\": [By.TAG_NAME, \"figure\", 117, 100],\n",
    "    # \"xpath_2\": [By.XPATH, \"/html/body/*\", 900, 0],\n",
    "    # \"img\": [By.TAG_NAME, \"img\", 28800, 900],\n",
    "}\n",
    "\n",
    "\n",
    "CHECKPOINT_1H = range(0, 432001, 3600)\n",
    "FLAG_CHECKPOINT_1H = [False for e in CHECKPOINT_1H]\n",
    "CHECKPOINT_10M = range(0, 432001, 600)\n",
    "FLAG_CHECKPOINTS_10M = [False for e in CHECKPOINT_10M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a410c-22d8-482a-b437-cdc37e343a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPERS\n",
    "def _get_search_url(query: str) -> str:\n",
    "    return f\"{SEARCH_URL}{query}&iar=images\"\n",
    "\n",
    "\n",
    "def _get_random(\n",
    "    *,\n",
    "    mean: float = NORMAL_MEAN,\n",
    "    std: float = NORMAL_STD,\n",
    "    size: float = NORMAL_SIZE,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "    value = NORMAL_GENERATOR.normal(loc = mean, scale = std, size = size)\n",
    "    return max(float(value[0]), 0.0011)\n",
    "\n",
    "\n",
    "def _log(t0: int, by_tag: int, by_val: int, max_val: int, curr_n: int, attempt_n: int, total_n: int, checkp: str) -> None:\n",
    "    tm = time()\n",
    "    stp = f\"[{str(dt.now()).split(\".\")[0]}]\"\n",
    "    msg = (\n",
    "        f\"{stp} Attempt {attempt_n}/{total_n} in: {by_tag}={by_val} with at least {max_val} elements.\\n\"\n",
    "        f\"{checkp} Total Time in {by_tag}={by_val} is {tm - t0:.2f}s | Current Elements: {curr_n}.\\n\"\n",
    "        f\"{\"-\"*110}\\n\"\n",
    "    )\n",
    "    print(msg, end=\"\")\n",
    "\n",
    "\n",
    "def _safeproof_click(driver, element_or_list, timeout=10):\n",
    "    # 1. Determine if it's a list or single element\n",
    "    target = element_or_list[0] if isinstance(element_or_list, list) else element_or_list\n",
    "    \n",
    "    try:\n",
    "        # 2. Wait until the element is actually clickable\n",
    "        wait = WebDriverWait(driver, timeout)\n",
    "        wait.until(EC.element_to_be_clickable(target))\n",
    "        \n",
    "        # 3. Try standard Selenium click (mimics real user)\n",
    "        target.click()\n",
    "    except Exception:\n",
    "        # 4. Fallback: JavaScript click (bypasses overlays/visibility issues)\n",
    "        driver.execute_script(\"arguments[0].click();\", target)\n",
    "\n",
    "\n",
    "def _click_on_xpath(xpath: str) -> None:\n",
    "    element_list: list[WebElement] = driver.find_elements(By.XPATH, xpath)\n",
    "    for element in element_list:\n",
    "        try:\n",
    "            element.click()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    \n",
    "# Remove empty elements and keep only unique elements\n",
    "def _unique_remove_empty(\n",
    "    element_list: list[WebElement],\n",
    ") -> list[WebElement]:\n",
    "    \"\"\"\n",
    "    - Removes empty inner lists\n",
    "    - Removes stale/broken WebElements\n",
    "    - Deduplicates WebElements globally (by element.id)\n",
    "    - Preserves order and grouping\n",
    "    \"\"\"\n",
    "\n",
    "    seen_ids: set[str] = set()\n",
    "    cleaned: list[WebElement] = []\n",
    "\n",
    "    try:\n",
    "        for el in element_list:\n",
    "            if el is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                el_id = el.id  # touching .id validates the element\n",
    "            except StaleElementReferenceException as ein:\n",
    "                continue\n",
    "\n",
    "            if el_id in seen_ids:\n",
    "                continue\n",
    "\n",
    "            seen_ids.add(el_id)\n",
    "            cleaned.append(el)\n",
    "\n",
    "    except Exception as eout:\n",
    "        cleaned = {x for x in element_list if x}\n",
    "        cleaned = list(cleaned)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def _remove_translate(web_element: str, base_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and decodes the real image URL from a DuckDuckGo image wrapper URL.\n",
    "    - Ignores exact base_url matching (robust to variations)\n",
    "    - Decodes percent-encoded URLs\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Parse and query\n",
    "    parsed = urlparse(web_element)\n",
    "    query = parse_qs(parsed.query)\n",
    "    \n",
    "    # 2. DuckDuckGo image links usually store the real URL in `iai`\n",
    "    if \"iai\" not in query:\n",
    "    \n",
    "        # 2.1.1. Normalize spaces encoded as '+'\n",
    "        normalized = web_element.replace(\"+\", \" \")\n",
    "    \n",
    "        # 2.1.2. Attempt direct removal if web_element starts with base_url\n",
    "        if normalized.startswith(base_url):\n",
    "            remainder = normalized[len(base_url):]\n",
    "        else:\n",
    "            # 2.1.3. Fuzzy match (threshold ≈ 90%)\n",
    "            ratio = difflib.SequenceMatcher(None, normalized[:len(base_url)], base_url).ratio()\n",
    "            if ratio >= 0.90:\n",
    "                remainder = normalized[len(base_url):]\n",
    "            else:\n",
    "                # 2.1.4. If no good match, fall back:\n",
    "                #    Find the first encoded \"http\" that is not the main one.\n",
    "                idx = normalized.find(\"http\", 5)  # skip the initial \"http\"\n",
    "                if idx == -1:\n",
    "                    return \"\"  # nothing usable found\n",
    "                remainder = normalized[idx:]\n",
    "    \n",
    "        # 2.1.5. Strip leading junk (&, ?, etc.)\n",
    "        while remainder.startswith((\"&\", \"?\", \"=\")):\n",
    "            remainder = remainder[1:]\n",
    "    \n",
    "        # 2.1.6. Decode URL-encoded parts\n",
    "        decoded_url = unquote(remainder)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        # 2.2.1. Parse_qs returns lists\n",
    "        encoded_url = query[\"iai\"][0]\n",
    "    \n",
    "        # 2.2.2. Decode percent-encoding\n",
    "        decoded_url = unquote(encoded_url)\n",
    "    \n",
    "    # 3. Remove trailing ?\n",
    "    if \"?\" in decoded_url[-20:]:\n",
    "        decoded_url = \"?\".join(decoded_url.split(\"?\")[:-1])\n",
    "    \n",
    "    return decoded_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10555683-2707-43b1-9e67-0436d96bbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "\n",
    "query: str = \"Olafur+Dari+Olafsson\"\n",
    "output_err_file: Path = Path(\"/Users/egg/Desktop/pics/notebooks/stderr.txt\")\n",
    "\n",
    "options: Options = Options()\n",
    "service: Service = Service(ChromeDriverManager().install())\n",
    "\n",
    "nav_window_size: tuple[int, int] = (1920, 1080)\n",
    "waiter_total_time_base: int = 20\n",
    "sleep_min_base: int = 0.1\n",
    "sleep_max_base: int = 2\n",
    "max_global_tries: int = 2\n",
    "max_local_tries: int = 5\n",
    "\n",
    "flag_checkpoint_1h = [False] * len(FLAG_CHECKPOINT_1H)\n",
    "flag_checkpoints_10m = [False] * len(CHECKPOINT_10M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadd64a-e1aa-493c-926a-64bf0551ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE\n",
    "\n",
    "# Input\n",
    "search_url = _get_search_url(query)\n",
    "\n",
    "# Driver Main\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Create window to maximize chance\n",
    "driver.maximize_window()\n",
    "driver.set_window_size(*nav_window_size)\n",
    "\n",
    "# Navigate to the URL\n",
    "driver.get(search_url)\n",
    "sleep(1)\n",
    "driver.refresh()\n",
    "sleep(1)\n",
    "\n",
    "print(f\"Search URL = {search_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bd365-1fee-45a5-87b6-d4a749d8b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver, duration=100)\n",
    "actions.scroll_by_amount(delta_x=0, delta_y = 100)\n",
    "sleep(sleep_min_base + _get_random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229950f-8deb-4224-83f8-7ef983444e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "actions = ActionChains(driver, duration=150)\n",
    "for i in range(0, 1000):\n",
    "    actions.scroll_by_amount(delta_x=0, delta_y = ceil(1 + _get_random()))\n",
    "actions.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7192ad-ee2e-4d44-8f73-7de7b2391249",
   "metadata": {},
   "source": [
    "## 2. Pre-Switches (clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fb54a-ce65-44c6-8a16-7f48eb1bc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch on Location Search\n",
    "\n",
    "def click_location_button() -> None:\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "\n",
    "    element_list = driver.find_elements(By.CSS_SELECTOR, \"[role='switch']\")\n",
    "    # print(f\"element_list = {element_list}\")\n",
    "\n",
    "    for element in element_list:\n",
    "\n",
    "        # print(f\"element = {element}\")\n",
    "\n",
    "        aria_checked: str = element.get_property(\"ariaChecked\")\n",
    "\n",
    "        # print(f\"aria_checked = {aria_checked} | type = ({type(aria_checked)})\")\n",
    "\n",
    "        if aria_checked is not None and aria_checked == \"false\":\n",
    "            try:\n",
    "                element.click()\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "        sleep(sleep_min_base + _get_random())\n",
    "    return\n",
    "\n",
    "click_location_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded1f19-fda5-4c31-872b-e9e785cf610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Location to USA and Image Size to Large\n",
    "\n",
    "def select_location_dropdown(\n",
    "    *,\n",
    "    target_text_list: list[str] = [\n",
    "        \"US (English)\",\n",
    "        \"US\",\n",
    "        \"USA\",\n",
    "        \"Estados Unidos (inglês)\",\n",
    "        \"Estados Unidos\",\n",
    "        \"United States (english)\",\n",
    "        \"United States\"\n",
    "    ]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "\n",
    "    # Change locale to US (English)\n",
    "    sleep(sleep_max_base + _get_random())\n",
    "    _click_on_xpath('//*[@id=\"react-layout\"]/div/div[2]/div/nav/div/ul/li[1]/div/div[1]')\n",
    "    sleep(sleep_min_base + _get_random())\n",
    "    _click_on_xpath('//*[@id=\"react-layout\"]/div/div[2]/div/nav/div/ul/li[1]/div/div[2]/div[2]/div[63]/div/div/div/span[2]')\n",
    "    sleep(sleep_max_base + _get_random())\n",
    "\n",
    "    # Changing Image Sizes to Large\n",
    "    sleep(sleep_max_base + _get_random())\n",
    "    _click_on_xpath('//*[@id=\"react-layout\"]/div/div[2]/div/nav/div/ul/li[5]/div/div[1]')\n",
    "    sleep(sleep_min_base + _get_random())\n",
    "    _click_on_xpath('//*[@id=\"react-layout\"]/div/div[2]/div/nav/div/ul/li[5]/div/div[2]/div/div[4]/div')\n",
    "    sleep(sleep_max_base + _get_random())\n",
    "\n",
    "select_location_dropdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77e1ef-924b-467d-80af-e51224937b6f",
   "metadata": {},
   "source": [
    "## 3. Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffac5c2-078c-418b-a11e-9662331f30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML\n",
    "\n",
    "# Find all <html> elements\n",
    "waiter = WebDriverWait(driver, sleep_max_base+waiter_total_time_base+_get_random())\n",
    "curr_element_list: list[WebElement] = waiter.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"html\")))\n",
    "\n",
    "# Print the number of <html> elements found\n",
    "print(f\"Found {len(curr_element_list)} html elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249d3a4-450d-4245-89e5-e4ef691c0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Loop\n",
    "\n",
    "for counter, (element_key, element_value) in enumerate(ELEMENT_DICT.items(), start=1):\n",
    "\n",
    "    t0 = time()\n",
    "    flag_condition_met: bool = False\n",
    "    \n",
    "    by_tag = element_value[0]\n",
    "    by_val = element_value[1]\n",
    "    max_val = element_value[3]\n",
    " \n",
    "    if max_val == 0:\n",
    "        max_val = element_value[2]\n",
    "\n",
    "    # if counter%10 == 0:\n",
    "    #     print(f\"{\"#\"*120}\")\n",
    "    #     print(f\"[STARTED] by_tag = {by_tag} | by_val = {by_val} | max_val = {max_val}\")\n",
    "    \n",
    "    if curr_element_list:\n",
    "        prev_element_list: list[WebElement] = curr_element_list.copy()\n",
    "        curr_element_list: list[WebElement] = []\n",
    "        flag_condition_met: bool = False\n",
    "        minimum_unique_elements: int = max_val if max_val > 3 else 1\n",
    "        flag_checkpoint_1h[:] = [False] * len(flag_checkpoint_1h)\n",
    "        flag_checkpoints_10m[:] = [False] * len(flag_checkpoints_10m)\n",
    "\n",
    "    # _log(t0, by_tag, by_val, max_val, len(curr_element_list), counter, max_global_tries, \"[Before-Loop]\")\n",
    "    \n",
    "    for glonen in range(max_global_tries):\n",
    "\n",
    "        if flag_condition_met:\n",
    "            break\n",
    "\n",
    "        for web_element in prev_element_list:\n",
    "\n",
    "            if flag_condition_met:\n",
    "                break\n",
    "\n",
    "            counter_hour: int = 0\n",
    "            counter_minute: int = 0\n",
    "            total_time_elapsed: int = 0\n",
    "            section_element_list: list[WebElement] = []\n",
    "            print(f\"Loading Attempt {glonen} of {max_global_tries}: .\", end=\"\")\n",
    "            for _ in range(max_local_tries):\n",
    "\n",
    "                if len(curr_element_list) >= minimum_unique_elements:\n",
    "                    flag_condition_met = True\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    section_element_list = waiter.until(EC.presence_of_all_elements_located((by_tag, by_val)))\n",
    "\n",
    "                except StaleElementReferenceException as sere:\n",
    "                    pass\n",
    "                except TimeoutException as toe:\n",
    "                    pass\n",
    "\n",
    "                if not section_element_list:\n",
    "                    continue\n",
    "\n",
    "                curr_element_list.extend(section_element_list)\n",
    "                curr_element_list: list[WebElement] = _unique_remove_empty(curr_element_list)\n",
    "                # sleep(sleep_min_base+_get_random())\n",
    "\n",
    "                if section_element_list:\n",
    "                    section_element_list: list[WebElement] = []\n",
    "\n",
    "                if len(curr_element_list) >= minimum_unique_elements:\n",
    "                    flag_condition_met = True\n",
    "                    break\n",
    "                    \n",
    "                t1 = time()\n",
    "                total_time_elapsed += (t1-t0)\n",
    "\n",
    "                if not flag_checkpoints_10m[counter_minute] and total_time_elapsed >= CHECKPOINT_10M[counter_minute]:\n",
    "                    # print(\".\", end=\"\")\n",
    "                    flag_checkpoints_10m[counter_minute] = True\n",
    "                    counter_minute += 1\n",
    "\n",
    "                    \n",
    "                if not flag_checkpoint_1h[counter_hour] and total_time_elapsed >= CHECKPOINT_1H[counter_hour]:\n",
    "                    # print(f\"|{(total_time_elapsed/3600):.2f}|\", end=\"\")\n",
    "                    flag_checkpoint_1h[counter_hour] = True\n",
    "                    counter_hour += 1\n",
    "\n",
    "                sleep(sleep_min_base + _get_random())\n",
    "            \n",
    "            # print(\".\\n\", end=\"\")\n",
    "            # _log(t0, by_tag, by_val, max_val, len(curr_element_list), counter, max_local_tries, \"[After-Loop]\")\n",
    "            if flag_condition_met or len(curr_element_list) >= minimum_unique_elements:\n",
    "                flag_condition_met = True\n",
    "                break\n",
    "        \n",
    "        # print(len(curr_element_list), minimum_unique_elements)\n",
    "        if flag_condition_met or len(curr_element_list) >= minimum_unique_elements:\n",
    "            flag_condition_met = True\n",
    "            break\n",
    "\n",
    "        # _log(t0, by_tag, by_val, max_val, len(curr_element_list), counter, max_global_tries, \"[End-Loop]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f620ff-0611-47df-86b5-e3171d75e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of URI List\n",
    "\n",
    "import difflib\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "# Getting baseURI property\n",
    "uri_list: list[str] = []\n",
    "for web_element in curr_element_list:\n",
    "    try:\n",
    "        web_element.click()\n",
    "        uri = web_element.get_property(\"baseURI\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    sleep(sleep_min_base + _get_random())\n",
    "    uri_list.append(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76678d8d-360d-42a0-a582-83e96156955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get links\n",
    "\n",
    "image_link_list: list[str] = []\n",
    "\n",
    "for uri in uri_list:\n",
    "    image_link = _remove_translate(uri, search_url)\n",
    "    image_link_list.append(image_link)\n",
    "\n",
    "print(f\"Image Link list has {len(image_link_list)} elements\")\n",
    "print(f\"# Sample Head:\\n{\"\\n\".join(image_link_list[:min(len(image_link_list), 10)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbcc41-55e9-4636-8f7e-3dcf98c459ca",
   "metadata": {},
   "source": [
    "## 4. Scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65156a-e9dc-4ec4-bcaf-7c0683dba81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll down for more images\n",
    "\n",
    "sleep(sleep_min_base + _get_random())\n",
    "# driver.refresh()\n",
    "sleep(sleep_min_base + _get_random())\n",
    "\n",
    "actions = ActionChains(driver)\n",
    "for _ in range(2):\n",
    "    actions.scroll_by_amount(delta_x=0, delta_y = nav_window_size[1])\n",
    "    sleep(sleep_min_base + _get_random())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bd439-9916-4c0a-b855-8adb3a174800",
   "metadata": {},
   "source": [
    "## 5. Novel Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d7119-f390-4681-ab41-7d1ff392f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML\n",
    "\n",
    "# Find all <html> elements\n",
    "waiter = WebDriverWait(driver, sleep_max_base+waiter_total_time_base+_get_random())\n",
    "curr_element_list: list[WebElement] = waiter.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"html\")))\n",
    "\n",
    "# Print the number of <html> elements found\n",
    "print(f\"Found {len(curr_element_list)} html elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4665ff9-d7f1-4170-8714-c8af2220802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter, (element_key, element_value) in enumerate(ELEMENT_DICT.items(), start=1):\n",
    "\n",
    "    t0 = time()\n",
    "    flag_condition_met: bool = False\n",
    "    \n",
    "    by_tag = element_value[0]\n",
    "    by_val = element_value[1]\n",
    "    max_val = element_value[3]\n",
    " \n",
    "    if max_val == 0:\n",
    "        max_val = element_value[2]\n",
    "\n",
    "    # if counter%10 == 0:\n",
    "    #     print(f\"{\"#\"*120}\")\n",
    "    #     print(f\"[STARTED] by_tag = {by_tag} | by_val = {by_val} | max_val = {max_val}\")\n",
    "    \n",
    "    if curr_element_list:\n",
    "        prev_element_list: list[WebElement] = curr_element_list.copy()\n",
    "        curr_element_list: list[WebElement] = []\n",
    "        flag_condition_met: bool = False\n",
    "        minimum_unique_elements: int = max_val if max_val > 3 else 1\n",
    "        flag_checkpoint_1h[:] = [False] * len(flag_checkpoint_1h)\n",
    "        flag_checkpoints_10m[:] = [False] * len(flag_checkpoints_10m)\n",
    "\n",
    "    # _log(t0, by_tag, by_val, max_val, len(curr_element_list), counter, max_global_tries, \"[Before-Loop]\")\n",
    "    \n",
    "    for glonen in range(max_global_tries):\n",
    "\n",
    "        if flag_condition_met:\n",
    "            break\n",
    "\n",
    "        for web_element in prev_element_list[::-1]:\n",
    "\n",
    "            counter_hour: int = 0\n",
    "            counter_minute: int = 0\n",
    "            total_time_elapsed: int = 0\n",
    "            section_element_list: list[WebElement] = []\n",
    "            print(f\"Loading Attempt {glonen} of {max_global_tries}: .\", end=\"\")\n",
    "            for _ in range(max_local_tries):\n",
    "                \n",
    "                try:\n",
    "                    section_element_list = waiter.until(EC.presence_of_all_elements_located((by_tag, by_val)))\n",
    "\n",
    "                except StaleElementReferenceException as sere:\n",
    "                    pass\n",
    "                except TimeoutException as toe:\n",
    "                    pass\n",
    "\n",
    "                if not section_element_list:\n",
    "                    continue\n",
    "\n",
    "                curr_element_list.extend(section_element_list)\n",
    "                curr_element_list: list[WebElement] = _unique_remove_empty(curr_element_list)\n",
    "                # sleep(sleep_min_base+_get_random())\n",
    "\n",
    "                if section_element_list:\n",
    "                    section_element_list: list[WebElement] = []\n",
    "\n",
    "                if len(curr_element_list) >= minimum_unique_elements:\n",
    "                    flag_condition_met = True\n",
    "                    continue\n",
    "                    \n",
    "                t1 = time()\n",
    "                total_time_elapsed += (t1-t0)\n",
    "\n",
    "                if not flag_checkpoints_10m[counter_minute] and total_time_elapsed >= CHECKPOINT_10M[counter_minute]:\n",
    "                    # print(\".\", end=\"\")\n",
    "                    flag_checkpoints_10m[counter_minute] = True\n",
    "                    counter_minute += 1\n",
    "\n",
    "                    \n",
    "                if not flag_checkpoint_1h[counter_hour] and total_time_elapsed >= CHECKPOINT_1H[counter_hour]:\n",
    "                    # print(f\"|{(total_time_elapsed/3600):.2f}|\", end=\"\")\n",
    "                    flag_checkpoint_1h[counter_hour] = True\n",
    "                    counter_hour += 1\n",
    "\n",
    "                sleep(sleep_min_base + _get_random())\n",
    "            \n",
    "            # print(\".\\n\", end=\"\")\n",
    "            # _log(t0, by_tag, by_val, max_val, len(curr_element_list), counter, max_local_tries, \"[After-Loop]\")\n",
    "            if flag_condition_met or len(curr_element_list) >= minimum_unique_elements:\n",
    "                flag_condition_met = True\n",
    "                break\n",
    "        \n",
    "        # print(len(curr_element_list), minimum_unique_elements)\n",
    "        if flag_condition_met or len(curr_element_list) >= minimum_unique_elements:\n",
    "            flag_condition_met = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf68c60-51cf-44d8-94a2-f4894a06f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting baseURI property\n",
    "new_uri_list: list[str] = []\n",
    "for web_element in curr_element_list:\n",
    "    try:\n",
    "        web_element.click()\n",
    "        uri = web_element.get_property(\"baseURI\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    sleep(sleep_min_base + _get_random())\n",
    "    new_uri_list.append(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d46be-773a-453c-82b7-d69206ec9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final of URI List\n",
    "\n",
    "new_image_link_list: list[str] = []\n",
    "\n",
    "for uri in new_uri_list:\n",
    "    image_link = _remove_translate(uri, search_url)\n",
    "    new_image_link_list.append(image_link)\n",
    "\n",
    "image_link_list.extend(new_image_link_list)\n",
    "\n",
    "final_uri_list: list[str] = list(set(uri_list))\n",
    "\n",
    "print(f\"Final URI list has {len(final_uri_list)} elements\")\n",
    "print(f\"# Sample Head:\\n{\"\\n\".join(final_uri_list[:min(len(final_uri_list), 10)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7abdf4-aba4-4b0c-a1a3-7183437a11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24141b5c-7d2c-4b71-9a27-221110329dcc",
   "metadata": {},
   "source": [
    "# Old Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e44725-14ab-447c-b9b2-dce21c62653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web_element = curr_element_list[0]\n",
    "# my_click = web_element.click()\n",
    "# print(my_click)\n",
    "\n",
    "# Getting baseURI property\n",
    "uri_list: list[str] = []\n",
    "for web_element in curr_element_list:\n",
    "    try:\n",
    "        web_element.click()\n",
    "        uri = web_element.get_property(\"baseURI\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    sleep(sleep_min_base + _get_random())\n",
    "    uri_list.append(uri)\n",
    "\n",
    "\n",
    "print(f\"There are {len(uri_list)} ULRs in uri_list\")\n",
    "\n",
    "# Final Links 1\n",
    "image_link_list: list[str] = []\n",
    "\n",
    "for uri in uri_list:\n",
    "    image_link = _remove_translate(uri, base_url: str)\n",
    "    image_link_list.append(image_link)\n",
    "\n",
    "print(f\"There are {len(image_link_list)} ULRs in image_link_list\")\n",
    "print(f\"Example: {image_link_list[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855f085-17ce-4808-ae48-434603ac91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote\n",
    "import difflib\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "base_url = search_url\n",
    "web_element = uri_list[1]\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24f3c5-0af2-4ebb-a7d1-c44aff936867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse\n",
    "parsed = urlparse(web_element)\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8279af6-9b48-4f6f-9487-85c5fb05c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Query\n",
    "query = parse_qs(parsed.query)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cd8c4-86d4-4c77-823c-d1a325846895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DuckDuckGo image links usually store the real URL in `iai`\n",
    "a = \"iai\" not in query\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f9a7b-1384-435f-906a-85393c81a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Parse_qs returns lists\n",
    "encoded_url = query[\"iai\"][0]\n",
    "print(encoded_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48677436-010e-410a-9cc6-7b6cd1cb7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Decode percent-encoding\n",
    "decoded_url = unquote(encoded_url)\n",
    "print(decoded_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fcaf4f-75e8-4fc0-a7aa-dd04dc10c686",
   "metadata": {},
   "source": [
    "### Separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecea704-faa8-42a4-aa51-0b9efafae184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize spaces encoded as '+'\n",
    "normalized = web_element.replace(\"+\", \" \")\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff424618-6358-4233-9f7d-4b5094be6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Attempt direct removal if web_element starts with base_url\n",
    "a = normalized.startswith(base_url)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973df18-e872-459c-b650-c9715ad122cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder = normalized[len(base_url):]\n",
    "print(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090b47d-1a6e-4c59-a814-a92485ebd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fuzzy match (threshold ≈ 90%)\n",
    "ratio = difflib.SequenceMatcher(None, normalized[:len(base_url)], base_url).ratio()\n",
    "b = ratio >= 0.90\n",
    "print(ratio)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcc6c0-e4fb-4d4f-a914-61ca090987cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder = normalized[len(base_url):]\n",
    "print(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39792a-fd25-4554-b86e-f03ffa8acb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. If no good match, fall back:\n",
    "#    Find the first encoded \"http\" that is not the main one.\n",
    "idx = normalized.find(\"http\", 5)  # skip the initial \"http\"\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3049303-416e-4b92-bda6-9d4dede296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder = normalized[idx:]\n",
    "print(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eaea07-01f3-4902-a77d-05d7205d74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Strip leading junk (&, ?, etc.)\n",
    "while remainder.startswith((\"&\", \"?\", \"=\")):\n",
    "    remainder = remainder[1:]\n",
    "print(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf514d2-f8f6-4731-aa47-e1b92ddecded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Decode URL-encoded parts\n",
    "decoded = unquote(remainder)\n",
    "if \"?\" in decoded[-20:]:\n",
    "    decoded = \"?\".join(decoded.split(\"?\")[:-1])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e39e4-2134-46f4-a1cb-b9e2de6ee40a",
   "metadata": {},
   "source": [
    "# Old Code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07cdee-5af6-4ed5-a817-879b9f7f2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting baseURI property\n",
    "uri_list: list[str] = []\n",
    "for web_element in curr_element_list:\n",
    "    try:\n",
    "        web_element.click()\n",
    "        uri = web_element.get_property(\"baseURI\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    sleep(sleep_min_base + _get_random())\n",
    "    uri_list.append(uri)\n",
    "\n",
    "\n",
    "print(f\"There are {len(uri_list)} ULRs in uri_list\")\n",
    "\n",
    "# Final Links 1\n",
    "image_link_list: list[str] = []\n",
    "\n",
    "for uri in uri_list:\n",
    "    image_link = _remove_translate(uri, base_url: str)\n",
    "    image_link_list.append(image_link)\n",
    "\n",
    "print(f\"There are {len(image_link_list)} ULRs in image_link_list\")\n",
    "print(f\"Example: {image_link_list[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4488d-b340-4be6-aa01-9862e3f2ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_location_dropdown(\n",
    "    *,\n",
    "    target_text_list: list[str] = [\n",
    "        \"US (English)\",\n",
    "        \"US\",\n",
    "        \"USA\",\n",
    "        \"Estados Unidos (inglês)\",\n",
    "        \"Estados Unidos\",\n",
    "        \"United States (english)\",\n",
    "        \"United States\"\n",
    "    ]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Placeholder\n",
    "    \"\"\"\n",
    "\n",
    "    def _walk_dfs(root: WebElement) -> Iterator[WebElement]:\n",
    "        stack = [root]\n",
    "        while stack:\n",
    "            element = stack.pop()\n",
    "            yield element\n",
    "            parent = element.get_property(\"parentNode\")\n",
    "            if parent:\n",
    "                stack.append(parent)\n",
    "            else:    \n",
    "                stack.append(\"False\")\n",
    "    \n",
    "    div_element_list = driver.find_elements(By.XPATH, \"//*[@data-testid='dropdown-options']\")\n",
    "\n",
    "    success_flag = False\n",
    "\n",
    "    for idx1, div_element in enumerate(div_element_list, start = 1):\n",
    "\n",
    "        print(f\"# Div {idx1} of {len(div_element_list)}: {div_element}\")\n",
    "        span_element_list = div_element.find_elements(By.TAG_NAME, \"span\")\n",
    "\n",
    "        for idx2, span_element in enumerate(span_element_list, start = 1):\n",
    "\n",
    "            outer_text: str = span_element.get_property(\"outerText\")\n",
    "            print(f\"    # Span {idx2} of {len(span_element_list)} has outer_text = {outer_text} | type = {type(outer_text)}\")\n",
    "\n",
    "            if outer_text:\n",
    "                for target_text in target_text_list:\n",
    "                    if target_text.strip().lower() == outer_text.strip().lower():\n",
    "\n",
    "                        try:\n",
    "                            driver.execute_script(\"arguments[0].click();\", span_element)\n",
    "                            span_element.click()\n",
    "                            success_flag = True\n",
    "                            break\n",
    "                        except Exception as e1:\n",
    "                            span_parent = span_element.get_property(\"parentNode\")\n",
    "                            for parent_element in _walk_dfs(span_parent):\n",
    "                                try:\n",
    "                                    parent_element.click()\n",
    "                                    success_flag = True\n",
    "                                    break\n",
    "                                except Exception as e2:\n",
    "                                    pass\n",
    "\n",
    "                    if success_flag:\n",
    "                        break\n",
    "            \n",
    "            if success_flag:\n",
    "                break\n",
    "\n",
    "        if success_flag:\n",
    "            break\n",
    "\n",
    "    sleep(1.0 + _get_random())\n",
    "    return\n",
    "\n",
    "select_location_dropdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7fb31-bb2c-43c4-b89f-8071e68064fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _ in range(0, 7):\n",
    "#element.get_property(\"parentNode\")\n",
    "#div_element_list = driver.find_elements(By.XPATH, \"//*[@data-testid='dropdown-options']\")\n",
    "\n",
    "# print(len(div_element_list))\n",
    "# div_children_list_1 = div_element_list[0].get_property(\"childNodes\")\n",
    "# print(len(div_children_list_1))\n",
    "# div_children_list_2 = div_children_list_1[0].get_property(\"childNodes\")\n",
    "# print(len(div_children_list_2))\n",
    "# div_children_list_3 = div_children_list_2[0].get_property(\"childNodes\")\n",
    "# print(len(div_children_list_3))\n",
    "\n",
    "# classname_0 = div_element_list[0].get_property(\"className\")\n",
    "# classname_1 = div_children_list_1[0].get_property(\"className\")\n",
    "# classname_2 = div_children_list_2[0].get_property(\"className\")\n",
    "# classname_3 = div_children_list_3[0].get_property(\"className\")\n",
    "\n",
    "# print(f\"classname_0: |{classname_0}|\")\n",
    "# print(f\"classname_1: |{classname_1}|\")\n",
    "# print(f\"classname_2: |{classname_2}|\")\n",
    "# print(f\"classname_3: |{classname_3}|\")\n",
    "\n",
    "# def select_location_dropdown(\n",
    "#     *,\n",
    "#     target_text_list: list[str] = [\n",
    "#         \"US (English)\",\n",
    "#         \"US\",\n",
    "#         \"USA\",\n",
    "#         \"Estados Unidos (inglês)\",\n",
    "#         \"Estados Unidos\",\n",
    "#         \"United States (english)\",\n",
    "#         \"United States\"\n",
    "#     ]\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Placeholder\n",
    "#     \"\"\"\n",
    "\n",
    "#     div_element_list = driver.find_elements(By.XPATH, \"//*[@data-testid='dropdown-options']\")\n",
    "    \n",
    "#     for current_element in walk_dfs(div_element_list):\n",
    "\n",
    "#         class_name = current_element.get_property(\"className\")\n",
    "#         outer_text = current_element.get_property(\"outerText\")\n",
    "\n",
    "#         if outer_text:\n",
    "#                 for target_text in target_text_list:\n",
    "#                     if target_text.strip().lower() == outer_text.strip().lower():\n",
    "\n",
    "\n",
    "#         if idx >= len(prev_element_list):\n",
    "            \n",
    "                        \n",
    "# #for element in \n",
    "# #print(len(span_element_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbb965-0609-426c-a559-7f2d8fdf6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BODY\n",
    "body_element_list = []\n",
    "\n",
    "for e in html_elements:\n",
    "\n",
    "    # Find all <body> elements\n",
    "    body_elements = e.find_elements(By.TAG_NAME, \"body\")\n",
    "    # body_elements = waiter.until(e.find_elements((By.TAG_NAME, \"body\")))\n",
    "    body_element_list.append(body_elements)\n",
    "    sleep(1)\n",
    "\n",
    "# Print the number of <body> elements found\n",
    "print(f\"Found {len(body_element_list)} body elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949bd865-4e9d-4364-99c0-6505c9245357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIV ID = \"web_content_wrapper\"\n",
    "divwebcont_element_list = []\n",
    "\n",
    "for sublist in body_element_list:\n",
    "    for e in sublist:\n",
    "\n",
    "        # Find all <div id=\"web_content_wraper\"> elements\n",
    "        divwebcont_elements = e.find_elements(By.ID, \"web_content_wrapper\")\n",
    "        # divwebcont_elements = waiter.until(e.find_elements((By.ID, \"web_content_wrapper\")))\n",
    "        divwebcont_element_list.append(divwebcont_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <div id=\"web_content_wraper\"> elements found\n",
    "print(f\"Found {len(divwebcont_element_list)} div ID=web_content_wrapper elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99610647-4a31-425e-bcea-433c485b18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIV XPATH = \"'//*[@id=\"react-layout\"]'\"\n",
    "divwebxpath_element_list = []\n",
    "\n",
    "for sublist in divwebcont_element_list:\n",
    "    for e in sublist:\n",
    "\n",
    "        # Find all <div xpath=\"'//*[@id=\"react-layout\"]'\"> elements\n",
    "        divwebxpath_elements = e.find_elements(By.XPATH, '//*[@id=\"react-layout\"]')\n",
    "        # divwebxpath_elements = waiter.until(e.find_elements((By.XPATH, '//*[@id=\"react-layout\"]')))\n",
    "        divwebxpath_element_list.append(divwebxpath_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <div xpath=\"XPATH=//*[@id='react-layout']\"> elements found\n",
    "print(f\"Found {len(divwebxpath_element_list)} div XPATH=//*[@id='react-layout'] elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982dbd3-15aa-4164-974c-5df39fc5edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(divwebxpath_element_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee225f7-c33b-4488-89dc-89d8d92bf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIV XPATH = \"//*[@id='react-layout']/div/div[2]/div/div[2]\"\n",
    "divwebxpathreact_element_list = []\n",
    "\n",
    "for sublist in divwebxpath_element_list:\n",
    "    for e in sublist:\n",
    "        \n",
    "        # Find all <div> elements\n",
    "        divwebxpathreact_elements = e.find_elements(By.XPATH, \"//*\")\n",
    "        # divwebxpathreact_elements = waiter.until(e.find_elements((By.XPATH, \"//*[@id='react-layout']/div/div[2]/div/div[2]\")))\n",
    "        divwebxpathreact_element_list.append(divwebxpathreact_elements)\n",
    "        sleep(3)\n",
    "\n",
    "# Print the number of <div xpath=\"//*[@id='react-layout']/div/div[2]/div/div[2]\"> elements found\n",
    "print(f\"Found {len(divwebxpathreact_element_list)} div XPATH=//*[@id='react-layout']/div/div[2]/div/div[2] elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6106e00-5f68-4f4e-8888-31f81999bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION\n",
    "section_element_list = []\n",
    "\n",
    "for sublist in divwebxpathreact_element_list:\n",
    "    for e in sublist:\n",
    "        \n",
    "        # Find all <section> elements\n",
    "        section_elements = e.find_elements(By.TAG_NAME, \"section\")\n",
    "        # section_elements = waiter.until(e.find_elements((By.TAG_NAME, \"section\")))\n",
    "        section_element_list.append(section_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <section> elements found\n",
    "print(f\"Found {len(section_element_list)} section elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e88282-1eec-4ec7-b532-1a925505982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_element_list = [e for e in section_element_list if e]\n",
    "print(f\"Found {len(section_element_list)} section elements\")\n",
    "print(section_element_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddced0-96ab-4f46-8b85-77fc6708e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OL 1\n",
    "ol_element_list_1 = []\n",
    "\n",
    "for sublist in section_element_list:\n",
    "    for e in sublist:\n",
    "    \n",
    "        # Find all <ol> elements\n",
    "        ol_elements = e.find_elements(By.TAG_NAME, \"ol\")\n",
    "        # ol_elements = waiter.until(e.find_elements((By.TAG_NAME, \"ol\")))\n",
    "        ol_element_list_1.append(ol_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <ol> elements found\n",
    "print(f\"Found {len(ol_element_list_1)} ol1 elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5d5d0-0380-446d-80f5-8999d4845b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_element_list_1 = [e for e in ol_element_list_1 if e]\n",
    "print(f\"Found {len(ol_element_list_1)} section elements\")\n",
    "print(ol_element_list_1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666897a-a9fa-461a-8824-6bc704277b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OL 2\n",
    "ol_element_list_2 = []\n",
    "\n",
    "for sublist in ol_element_list_1:\n",
    "    for e in sublist:\n",
    "\n",
    "        # Find all <ol> elements\n",
    "        ol_elements = e.find_elements(By.TAG_NAME, \"ol\")\n",
    "        # ol_elements = waiter.until(e.find_elements((By.TAG_NAME, \"ol\")))\n",
    "        ol_element_list_2.append(ol_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <ol> elements found\n",
    "print(f\"Found {len(ol_element_list_2)} ol2 elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc781a48-dde7-47da-8dfa-0e465235e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_element_list_2 = [e for e in ol_element_list_2 if e]\n",
    "print(f\"Found {len(ol_element_list_2)} section elements\")\n",
    "print(ol_element_list_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e6d8c-f16d-4949-a3e9-51a2dcaa5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE\n",
    "figure_element_list = []\n",
    "\n",
    "for sublist in ol_element_list_2:\n",
    "    for e in sublist:\n",
    "\n",
    "        # Find all <figure> elements\n",
    "        figure_elements = e.find_elements(By.TAG_NAME, \"figure\")\n",
    "        # figure_elements = waiter.until(e.find_elements((By.TAG_NAME, \"figure\")))\n",
    "        figure_element_list.append(figure_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <figure> elements found\n",
    "print(f\"Found {len(figure_element_list)} figure elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33821f-ff29-4e70-9f7c-647ecc4e1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_element_list = [e for e in figure_element_list if e]\n",
    "print(f\"Found {len(figure_element_list)} section elements\")\n",
    "print(figure_element_list[:1][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c6df5-749d-47e7-bdab-7a7f850c7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIV XPATH = \"/html/body/div[2]/div[6]/div[4]/div/div[2]/div/div[2]/section/ol/li[1]/ol/li[1]/figure/div[1]\"\n",
    "divwebxpathreact_body_li_element_list = []\n",
    "\n",
    "for sublist in figure_element_list:\n",
    "    for e in sublist:\n",
    "\n",
    "        # Find all <div xpath=\"/html/body/div/ol/li/figure/div\"> elements\n",
    "        divwebxpathreact_body_li_elements = e.find_elements(By.XPATH, \"/html/body/*\")\n",
    "        # divwebxpathreact_body_li_elements = waiter.until(e.find_elements((By.XPATH, \"/html/body/div[2]/div[6]/div[4]/div/div[2]/div/div[2]/section/ol/li[1]/ol/li[1]/figure/div[1]\")))\n",
    "        divwebxpathreact_body_li_element_list.append(divwebxpathreact_body_li_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <div xpath=\"/html/body/div/ol/li/figure/div\"> elements found\n",
    "print(f\"Found {len(divwebxpathreact_body_li_element_list)} div XPATH=/html/body/div/ol/li/figure/div elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872fcc2-89ab-4ea8-84f5-f4e89671e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG\n",
    "img_element_list = []\n",
    "\n",
    "for sublist in divwebxpathreact_body_li_element_list:\n",
    "    for e in sublist:\n",
    "\n",
    "        # Find all <img> elements\n",
    "        img_elements = e.find_elements(By.TAG_NAME, \"img\")\n",
    "        # img_elements = waiter.until(e.find_elements((By.TAG_NAME, \"img\")))\n",
    "        img_element_list.append(img_elements)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <img> elements found\n",
    "print(f\"Found {len(img_element_list)} img elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e3ccb-a938-4000-9cf6-8ef3f2cda9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_element_list = [e for e in img_element_list if e]\n",
    "print(f\"Found {len(img_element_list)} img elements\")\n",
    "print(img_element_list[:1][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3500ed-3bc5-4a80-8920-1b4dfeadf93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINKS\n",
    "# \"https://duckduckgo.com/?q=Olafur+Dari+Olafsson&iar=images&iai=https%3A%2F%2Fknightedgemedia.com%2Fwp-content%2Fuploads%2F2025%2F12%2Folafur-darri-olafsson-max-parker-god-of-war-banner.jpg\"\n",
    "# \"https://knightedgemedia.com/wp-content/uploads/2025/12/olafur-darri-olafsson-max-parker-god-of-war-banner.jpg\"\n",
    "\n",
    "link_list = []\n",
    "\n",
    "for sublist in img_element_list:\n",
    "    for e in sublist:\n",
    "        \n",
    "        # Find all links\n",
    "        link = e.find_elements(By.CSS_SELECTOR, \"baseURI\")\n",
    "        # img_elements = waiter.until(e.find_elements((By.TAG_NAME, \"img\")))\n",
    "        link_list.append(link)\n",
    "        sleep(1)\n",
    "\n",
    "# Print the number of <img> elements found\n",
    "print(f\"Found {len(link_list)} links with baseURI elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d1ba4-8771-4338-ab69-7e247f9daa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = [e for e in link_list if e]\n",
    "print(f\"Found {len(link_list)} img elements\")\n",
    "print(link_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd718551-8ca8-4c54-b6be-d3453048b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check any name\n",
    "def print_element(element, output_path: Path, mode):\n",
    "    with open(output_path, mode, encoding=\"utf-8\") as file:\n",
    "\n",
    "        pref_list = [\"\", \"tag_\", \"item_\"]\n",
    "        suff_list = [\"name\", \"id\", \"class\", \"style\"]\n",
    "        names = dict()\n",
    "        for pref in pref_list:\n",
    "            for suff in suff_list:\n",
    "                name = pref + suff\n",
    "                value1 = element.get_attribute(name) or None\n",
    "                value2 = getattr(element, name, None)\n",
    "                value = value1\n",
    "                if not value1 and not value2:\n",
    "                    continue\n",
    "                elif value1 and value2:\n",
    "                    value = (value1, value2)\n",
    "                    if value1 == value2:\n",
    "                        value = value1\n",
    "                elif not value1:\n",
    "                        value = value2\n",
    "                names[name] = value\n",
    "        for k, v in names.items():\n",
    "            file.write(f\"# {k}: {v}\\n\")\n",
    "            file.write(f\"{\"-\"*50}\\n\")\n",
    "        file.write(f\"\\n{\"=\"*100}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d572bf-23d6-46d4-85e4-7bc48309667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Large Images\n",
    "def download_large_images(driver, waiter, min_width, min_height):\n",
    "    \"\"\"Downloads images larger than the specified dimensions.\"\"\"\n",
    "    \n",
    "    images = waiter.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"img\")))\n",
    "\n",
    "    for img in images:\n",
    "        try:  # use try-except for error handling\n",
    "            src = img.get_attribute(\"src\")\n",
    "            if src:  # check if src attribute exists\n",
    "                response = requests.get(src, stream=True)\n",
    "                response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "                image = Image.open(BytesIO(response.content))  # Open the image using PIL\n",
    "                width, height = image.size  # Get the image size\n",
    "\n",
    "                if width > min_width and height > min_height:\n",
    "                    print(f\"Downloading: {src}\")\n",
    "                    # Save the image (you'll need to determine the filename)\n",
    "                    image.save(f\"image_{width}x{height}.jpg\")  # Example filename\n",
    "            else:\n",
    "                print(\"Image has no src attribute\") \n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# for element in clickable_elements:\n",
    "#     element_name = element.get_attribute(\"name\") or element.get_attribute(\"id\") or element.tag_name\n",
    "#     print(f\"Clicked element: {element_name}\")\n",
    "#     element.click()\n",
    "#     WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"img\"))) # wait for at least one img tag\n",
    "#     download_large_images(driver, 200, 200) # example dimensions\n",
    "#     driver.back() # go back to the main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22062c9-28a3-4ca9-9b34-bac673947df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheats to work in headless mode\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "sleep(1)\n",
    "driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "sleep(2)\n",
    "driver.refresh()\n",
    "\n",
    "# Cheats to work in headless mode\n",
    "\n",
    "\n",
    "actions.move_by_offset(100, 100).perform()\n",
    "sleep(1)\n",
    "actions.move_by_offset(-50, -50).perform()\n",
    "sleep(1)\n",
    "driver.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711eb128-8cc7-4a93-8233-93e400552869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the <img> elements\n",
    "img_elements = driver.find_elements(By.TAG_NAME, \"img\")\n",
    "\n",
    "# Print the number of <img> elements found\n",
    "print(f\"Found {len(img_elements)} img elements\")\n",
    "\n",
    "# Find all the <img> elements\n",
    "img_elements = driver.find_elements(By.CSS_SELECTOR, \"nodeName: IMG\")\n",
    "\n",
    "# Print the number of <img> elements found\n",
    "print(f\"Found {len(img_elements)} img elements\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93f525-4c98-4400-820b-a15ddc019d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the <ol> elements\n",
    "ol_elements = driver.find_elements(By.TAG_NAME, \"ol\")\n",
    "\n",
    "# Add a wait for the ol elements to appear\n",
    "# ol_elements = waiter.until(EC.presence_of_element_located((By.TAG_NAME, \"OL\")))\n",
    "\n",
    "# Print the number of <ol> elements found\n",
    "print(f\"Found {len(ol_elements)} ol elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18484bab-58ab-4dfa-88a8-33b53d247162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in img_elements:\n",
    "    print(element)\n",
    "    #print_element(element, output_err_file, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc3b85-e3de-456f-93da-bda9165490c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, print the text content of each <ol> element\n",
    "for ol in ol_elements:\n",
    "    print(ol)\n",
    "    value = ol.get_attribute(\"textContent\")\n",
    "    # print_element(element, output_err_file, mode=\"w\")\n",
    "    print(value)\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae631a2-218c-4d89-b859-46986316c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for clickeable items\n",
    "with open(output_err_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for ol1 in ol1_elements:\n",
    "        try:\n",
    "            # Find clickable elements *within* the current <ol>\n",
    "            # This assumes the clickable elements are <a> tags; adjust if needed\n",
    "            # Add a wait for the a elements to appear\n",
    "            ol2_elements = waiter.until(ol.find_elements((By.TAG_NAME, \"ol\")))\n",
    "\n",
    "            for ol2 \n",
    "            \n",
    "            for element in clickable_elements:\n",
    "                try:\n",
    "\n",
    "                    # Check any name\n",
    "                    ename = element.get_attribute(\"name\") or None\n",
    "                    eid = element.get_attribute(\"id\") or None\n",
    "                    etag_name = element.get_attribute(\"tag_name\") or None\n",
    "                    tag_name = getattr(element, \"tag_name\", None)\n",
    "                    file.write(f\"{\"#\"*30} {ename} | {eid} | {etag_name} | {tag_name}\\n\")\n",
    "                    \n",
    "                    #Click on the element\n",
    "                    element.click()\n",
    "\n",
    "                    # Go back to the main page\n",
    "                    waiter.until(driver.back())\n",
    "                    \n",
    "                    #Re-find the ol elements, as the page might have changed\n",
    "                    ol_elements = waiter.until(EC.presence_of_all_elements_located((By.TAG_NAME, \"ol\")))\n",
    "                    break #break to the parent loop.\n",
    "                except Exception as e:\n",
    "                    stp = f\"[{str(dt.now()).split(\".\")[0]}] \"\n",
    "                    file.write(f\"{stp}Could not click element: {e}\\n\")\n",
    "                    file.write(f\"{\"-\"*100}\\n\\n\")\n",
    "                    continue\n",
    "    \n",
    "        except Exception as e:\n",
    "            stp = f\"[{str(dt.now()).split(\".\")[0]}] \"\n",
    "            file.write(f\"{stp}Could not find elements in ol: {e}\\n\")\n",
    "            file.write(f\"{\"-\"*100}\\n\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f747468-c2b3-4afb-8b2f-8974caead43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = f\"[{str(dt.now()).split(\".\")[0]}] \"\n",
    "print(stp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee50b07-39d5-41fc-9eb0-cff8a73e44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "t1 = time()\n",
    "sleep(1+_get_random())\n",
    "t2 = time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be79cab-caa2-4533-878f-d157220917a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
